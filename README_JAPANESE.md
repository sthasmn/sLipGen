# LipGen: 自動アクティブスピーカー文単位ビデオ生成

## 概要

**LipGen** は、**文単位のアクティブスピーカービデオクリップ**を生の動画から生成するパイプラインです。  
このシステムは **音声文字起こし** と **アクティブスピーカー検出** を組み合わせ、発話ごとに **正しい顔トラック動画** と対応させます。

これにより以下が可能になります：
- 発話ごとの **文単位で顔を切り出した動画クリップ** を自動抽出  
- TV番組やインタビューなどの **in-the-wild 動画** に対応  
- 出力結果を **リップリーディングデータセット** や **コミュニケーション研究**、その他のマルチモーダルAI用途に活用

---

## 動作の仕組み

ワークフローは以下の2つの主要コンポーネントを統合しています：

1. **アクティブスピーカー検出 (LR-ASD)**  
   - [LR-ASD リポジトリ](https://github.com/Junhua-Liao/LR-ASD) に基づく  
   - 顔を検出し、フレーム間で追跡、どのスピーカーが話しているかを推定  
   - 中間ファイルを生成：
     - `pyavi/` : 25fpsにリサンプルした動画と音声 (`audio.wav`)  
     - `pyframes/` : 抽出フレーム  
     - `pywork/` : メタデータ (`faces.pckl`, `tracks.pckl`, `scores.pckl` など)  
     - `pycrop/` : 顔トラック動画の切り出し  

2. **音声文字起こし (Whisper)**  
   - LR-ASDで生成された **リサンプル音声** (`pyavi/audio.wav`) に対して実行  
   - 発話を **文単位に分割** し、開始・終了時刻を取得  
   - 結果は `manifest.json` に保存  

3. **文単位とスピーカーの対応付け**  
   - 各文の文字起こし結果を、該当時間に重なる **アクティブスピーカートラック** に対応させる  
   - 発話中の **話している人物の顔だけを含む動画クリップ** を生成  
   - 音声も保持され、発話内容と一致する動画が出力される

---

## メインスクリプト

主な作業スクリプトは以下です：

```bash
runner.py
```

### 特徴
- 入力: 生の動画ファイル  
- 出力: 文単位の **アクティブスピーカークリップ**（動画＋音声）  
- LR-ASD処理とWhisper文字起こしを自動処理  
- オプションフラグ：
  - `--skip_asd` : 既に `pywork/` や `pyavi/` が存在する場合はLR-ASDをスキップ（処理時間短縮）

---

## ワークフロー概要

1. **LR-ASD を実行** し、リサンプル動画・音声と顔トラックを生成  
2. **Whisper を実行** し、文ごとのタイムスタンプを取得  
3. **文とアクティブスピーカーを対応付け** LR-ASDのスコアとトラックメタデータを使用  
4. **発話している顔だけを含むクリップを出力** 音声も同期  

---

## 使用例

```bash
# 標準使用例 (LR-ASD + Whisper + 対応付けを実行)
python runner.py input_folder

# 既に前処理済みの場合はLR-ASDをスキップ
python runner.py input_foledr --skip_asd
```

## 出力
- **manifest.json :** Whisper文字起こし結果とリサンプル音声の対応  
- **clips/ :** 各発話ごとに生成される動画、アクティブスピーカーの顔と音声を含む  

## 活用例
- リップリーディング用データセット生成（日本語や他言語）  
- 発話障害者向け支援技術  
- メディア解析（TV番組、インタビュー、パネルディスカッション）  
- 音声・映像を組み合わせたマルチモーダルAI研究  

## 今後の計画
- [x] 基本的なLR-ASD統合  
- [x] Whisperによる文単位文字起こし  
- [x] 文とスピーカーの対応付け  
- [x] 動画クリップの出力（音声付き）  
- [ ] 発話者の目視確認  
- [ ] multiprocessingの実行  (要確認)
- [ ] 複数PCから同時に実行（PC募集中） 

## 検証
| Model          | whisper                                     | whisperx                         | ReazonSpeech |
|----------------|---------------------------------------------|----------------------------------|--------------|
| base           |                                             |                                  |        |
| medium         |                                             | 57 sentences. Audio Alignment NG |        |
| large-v2       |                                             |        57 sentences. Audio Alignment NG                          |        |
| large-v3-turbo | 689 sentences. need to confirm alignments.  |                                  |        |

## 参考文献
- LR-ASD: アクティブスピーカー検出  
- OpenAI Whisper

